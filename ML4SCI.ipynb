{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML4SCI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-aMZDq8is4X"
      },
      "source": [
        "# importing important libraries\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import seaborn as sns\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn import linear_model\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.linear_model import LassoCV\r\n",
        "from yellowbrick.regressor import AlphaSelection\r\n",
        "from sklearn.linear_model import Ridge\r\n",
        "from yellowbrick.regressor import ManualAlphaSelection\r\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l2UIEd3i7nY"
      },
      "source": [
        "# columns are given as names as given in pdf file\r\n",
        "#two dataset file, dataset and dataset1 are made one for visualization and other one for modeling.\r\n",
        "\r\n",
        "my_cols = ['Param1','Param1_un','Param2','Param2_un','Param3','TMass','NiMass','Explosion energy','Snela Mass','Ni Mass']\r\n",
        "dataset = pd.read_csv(\"/content/dataset.csv\", header  = None,usecols= range(10), names = my_cols)\r\n",
        "dataset1 = pd.read_csv(\"/content/dataset.csv\", header  = None,usecols= range(10), names = my_cols )"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWUruj93nNVH"
      },
      "source": [
        "# optical depth, maximum velocity and emergent flux of gamma-rays are standarized for smooth modelling\r\n",
        "# dataset is used for data visualization\r\n",
        "\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "dataset[['Param1','Param2','Param3']] = MinMaxScaler().fit_transform(dataset[['Param1','Param2','Param3']])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H1AO_AokcXM"
      },
      "source": [
        "# the observable variables are plotted against each other\r\n",
        "# kde plot of seaborn is used for plotting \r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plt.figure(figsize=(8,5), dpi= 80)\r\n",
        "sns.kdeplot(dataset[\"Param1\"], shade=True, color=\"g\", label=\"Optical depth\", alpha=.6)\r\n",
        "sns.kdeplot(dataset[\"Param2\"], shade=True, color=\"r\", label=\"V max\", alpha=.6)\r\n",
        "sns.kdeplot(dataset[\"Param3\"], shade=True, color=\"b\", label=\"Flux of gamma rays\", alpha=.6)\r\n",
        "plt.xlabel('Standarize value')\r\n",
        "plt.title('Observable Parameters plotted against each other (standarize)')\r\n",
        "plt.legend()\r\n",
        "plt.savefig(\"Observable Parameters Plotted \",dpi = 300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcWDKeIwxRGF"
      },
      "source": [
        "# optical depth value is plotted with adding errors \r\n",
        "# no standarization has been done\r\n",
        "# kde has been used again\r\n",
        "\r\n",
        "plt.figure(figsize=(8,5), dpi= 80)\r\n",
        "sns.kdeplot(dataset1[\"Param1\"], shade=True, color=\"g\", label=\" Actual Optical depth\", alpha=1)\r\n",
        "sns.kdeplot(dataset1[\"Param1\"] + dataset1[\"Param1_un\"], shade=True,label=\"with positive error\", color=\"b\", alpha=.6)\r\n",
        "sns.kdeplot(dataset1[\"Param1\"] - dataset1[\"Param1_un\"], shade=True,label=\"with negative error\" ,color=\"r\", alpha=.6)\r\n",
        "plt.xlabel('Actual value')\r\n",
        "plt.title('Optical depth plotted ( not standarize)')\r\n",
        "plt.legend()\r\n",
        "plt.savefig(\"Optical depth Plotted \",dpi = 300)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqCgY2ho4ZNN"
      },
      "source": [
        "# V max value is plotted with adding errors \r\n",
        "# no standarization has been done\r\n",
        "# kde has been used again\r\n",
        "\r\n",
        "plt.figure(figsize=(8,5), dpi= 80)\r\n",
        "sns.kdeplot(dataset1[\"Param2\"], shade=True, color=\"g\", label=\"Actual V max\", alpha=1)\r\n",
        "sns.kdeplot(dataset1[\"Param2\"] + dataset1[\"Param2_un\"], shade=True, color=\"b\", label=\"with positive error\", alpha=.6)\r\n",
        "sns.kdeplot(dataset1[\"Param2\"] - dataset1[\"Param2_un\"], shade=True, color=\"r\", label=\"with negative error\", alpha=.6)\r\n",
        "plt.xlabel('Actual value')\r\n",
        "plt.title('Velocity max plotted ( not standarize)')\r\n",
        "plt.legend()\r\n",
        "plt.savefig(\"Velocity max Plotted \",dpi = 300)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5lCqBR66nYW"
      },
      "source": [
        "# emergent flux of gamma rays is plotted  \r\n",
        "# no standarization has been done\r\n",
        "# kde has been used again\r\n",
        "\r\n",
        "plt.figure(figsize=(8,5), dpi= 80)\r\n",
        "sns.kdeplot(dataset1[\"Param3\"], shade=True, color=\"c\", label=\"Emergent flux of gamma\", alpha=0.8)\r\n",
        "plt.xlabel('Actual value')\r\n",
        "plt.title('Emergent Flux of Gamma plotted ( not standarize)')\r\n",
        "plt.legend()\r\n",
        "plt.savefig(\"Emrergent Flux\",dpi = 300)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi3aSixHD_dX"
      },
      "source": [
        "# Correlation heatmap has been made\r\n",
        "\r\n",
        "plt.figure(figsize=(8,5), dpi= 80)\r\n",
        "sns.heatmap(dataset1.corr(), annot = True,square=True,cmap= 'coolwarm')\r\n",
        "plt.title('Correlation heatmap', fontsize = 28)\r\n",
        "plt.savefig(\"Correlation Heatmap\",dpi = 300)\r\n",
        "dataset1.corr().to_csv(\"correlation.csv\",index = True, header = True)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyBs1BOwGDmi"
      },
      "source": [
        "# Snela Mass distribution flag  and Ni Mass distribution  flag is hot encoded.\r\n",
        "# LabelEncoder() is used \r\n",
        "# the hot-encoding is attached to dataset with column name \"Snela Flag Label\" and \"Ni Flag Label\" \r\n",
        "\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "labelencoder = LabelEncoder()\r\n",
        "dataset[\"Snela Flag label\"] = labelencoder.fit_transform(dataset1[\"Snela Mass\"])\r\n",
        "dataset[\"Ni Flag label\"] = labelencoder.fit_transform(dataset1[\"Ni Mass\"])\r\n",
        "labelencoder.transform(['N100', 'hed8', 'mwd' ,'w7dt'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv34JPGnOchz"
      },
      "source": [
        "# two list are initialized\r\n",
        "# one for going over type of flag and another one for going over which mass distribution\r\n",
        "\r\n",
        "list11 = list(labelencoder.classes_)\r\n",
        "list12 = list(['Snela Mass','Ni Mass'])\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2K65k4bQ1Lq"
      },
      "source": [
        "# graphs are made to analyze how a type of flag ['N100', 'hed8', 'mwd' ,'w7dt'] in both of \"Snela Mass Flag\" or \"Ni Mass Flag\" varies with \r\n",
        "# observable parameters\r\n",
        "# two for loops are made one for going over \"Snela Mass Flag\" or \"Ni Mass Flag\" and another one for going over type of flag ['N100', 'hed8', 'mwd' ,'w7dt']\r\n",
        "# total 8 graphs are made\r\n",
        "\r\n",
        "for outer_index in range(2):\r\n",
        "  for inner_index in range(4):\r\n",
        "    plt.figure(figsize=(8,5), dpi= 80)\r\n",
        "    data_index = dataset[dataset[list12[outer_index]] == list11[inner_index]]\r\n",
        "    plot = sns.kdeplot(data_index[\"Param1\"], shade=True, color=\"g\", label=\"Optical depth\", alpha=.6)\r\n",
        "    sns.kdeplot(data_index[\"Param2\"], shade=True, color=\"r\", label=\"V max\", alpha=.6)\r\n",
        "    sns.kdeplot(data_index[\"Param3\"], shade=True, color=\"b\", label=\"Flux of gamma rays\", alpha=.6)\r\n",
        "    plt.title('graph of ' + str(list12[outer_index]) + ' flag distribution of type ' + str(list11[inner_index]))\r\n",
        "    plt.xlabel('Actual value (not standarize)')\r\n",
        "    data_index.corr().to_csv(str(list12[outer_index]) +\" \"+ str(list11[inner_index] + \".csv\"),index = True,header = True)\r\n",
        "    plt.legend()\r\n",
        "    plt.savefig(str(list12[outer_index]) +\" \" +  str(list11[inner_index]),dpi = 300)\r\n",
        "    plt.show()\r\n",
        "    #plot.get_figure().clf()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA9gzm4uPIlA"
      },
      "source": [
        "# dataset1 is used for modelling process as 'dataset' standarize and we don't need standarize data for linear regression and \r\n",
        "# RandomForestClassifier is already, one hot encoding is attached with \"Snela Flag Label\" and \"Ni Flag label\" column\r\n",
        "\r\n",
        "dataset1[\"Snela Flag label\"] = labelencoder.fit_transform(dataset1[\"Snela Mass\"])\r\n",
        "dataset1[\"Ni Flag label\"] = labelencoder.fit_transform(dataset1[\"Ni Mass\"])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysjTtYFtPsnu"
      },
      "source": [
        "# physical_parameters is list of all physical parameters\r\n",
        "# columns is list of cloumn names of all the observable parameters \r\n",
        "# model is list of models which function linear_regression_compression  will make\r\n",
        "\r\n",
        "physical_parameters = ['TMass','NiMass','Explosion energy',\"Snela Flag label\",\"Ni Flag label\"]\r\n",
        "columns = ['Param1','Param2','Param3']\r\n",
        "model = ['model_TMass','model_Nimass','model_explosion energy','model_Snela_flag','model_Ni_flag']"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ_u4SVxzJor"
      },
      "source": [
        "# a function metric_evaluation is made to compare the regression model efficiency\r\n",
        "# this function will be called in another function \r\n",
        "\r\n",
        "def metric_evaluation (y_test,pred):\r\n",
        "  a = metrics.mean_absolute_error(y_test,pred)\r\n",
        "  b = metrics.mean_squared_error(y_test,pred)\r\n",
        "  c = np.sqrt(metrics.mean_squared_error(y_test,pred))\r\n",
        "  return [a,b,c]\r\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da2L_AdnU5gK"
      },
      "source": [
        "# linear_regression_model directly gives all the models and the efficiency of a particular model when train and test dataset are fed to this function.\r\n",
        "def linear_regression_comparision (given_data):\r\n",
        "\r\n",
        "# two for loops are made one for making linear regression models and another one for classification model (RandomforestClassifier is used)\r\n",
        "# data is splitted with train_test_split in ratio of 0.2 and only selected data is given.\r\n",
        "# selected data means that all observable parameters and the physical parameters which is needed is only given for training and testing\r\n",
        "\r\n",
        "  for indexing in range(3):\r\n",
        "  \r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(given_data[columns],given_data[physical_parameters[indexing]] ,test_size = 0.2,random_state = 45)\r\n",
        "    \r\n",
        "    # train and test data are standarize after splitting to avoid any type of baisness one dataset can put into another\r\n",
        "    \r\n",
        "    \r\n",
        "    #X_train = scaler.fit_transform(X_train)\r\n",
        "    #X_test = scaler1.fit_transform(X_test)\r\n",
        "\r\n",
        "    print(physical_parameters[indexing])\r\n",
        "    \r\n",
        "    print(\"linear_regression\")\r\n",
        "    model[indexing] = linear_model.LinearRegression()\r\n",
        "    model[indexing].fit(X_train,y_train)\r\n",
        "    pred = model[indexing].predict(X_test)\r\n",
        "    \r\n",
        "    # metric_evaluaiton function is called to evaluate the model\r\n",
        "\r\n",
        "    MAE, MSE , RSQUARE = metric_evaluation(y_test,pred)\r\n",
        "    print(\"MAE =\" , MAE,\"MSE = \", MSE ,\"RSQUARE = \",RSQUARE)\r\n",
        "    print(\"--------\")\r\n",
        "\r\n",
        "  for index in range(2):\r\n",
        "\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(given_data[columns],given_data[physical_parameters[index + 3]] ,test_size = 0.2,random_state = 45)\r\n",
        "   \r\n",
        "    # in RandomForestClassifier we have not standarization of data has been done\r\n",
        "\r\n",
        "    print(physical_parameters[index + 3])\r\n",
        "    print(\"Random Forest Classifier\")\r\n",
        "    \r\n",
        "    # n_estimators = 500\r\n",
        "\r\n",
        "    model[index + 3]=RandomForestClassifier(n_estimators=500)\r\n",
        "    model[index + 3].fit(X_train,y_train)\r\n",
        "    pred=model[index + 3].predict(X_test) \r\n",
        "    \r\n",
        "    print(\"Accuracy:\",metrics.accuracy_score(y_test, pred))\r\n",
        "    print(\"----------\")\r\n",
        "\r\n",
        "  # all the models which are made for each physical parameters are returned \r\n",
        "  return model\r\n",
        "\r\n",
        "    # lasso and ridge are not suggessted as these models are used when number of input variable are very large (around 12-15), here 3\r\n",
        "    # the change in alpha value literally did not affected much when tried on this dataset\r\n",
        "\r\n",
        "\r\n",
        "    #lasso = LassoCV(alphas=alphas)\r\n",
        "    #visualizer = AlphaSelection(lasso)\r\n",
        "    #visualizer.fit(X_train, y_train)\r\n",
        "    #plt.legend()\r\n",
        "    #visualizer.show()\r\n",
        "\r\n",
        "    #Ridge_model = ManualAlphaSelection(Ridge(),alphas=alphas,cv=12,scoring=\"neg_mean_squared_error\")\r\n",
        "    #Ridge_model.fit(X_train, y_train)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhWtEkqKkdqP"
      },
      "source": [
        "model1,model2,model3,model4,model5 =  linear_regression_comparision(dataset1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tziTSzFBA4kH"
      },
      "source": [
        "data = [[3.35,0.015,0.000012],[2.54,0.013,0.00000502],[2.46,0.013,0.0000103]]\r\n",
        "test = pd.DataFrame(data,columns = ['Param1','Param2','Param3'])\r\n",
        "test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idJaYECkPPE5"
      },
      "source": [
        "#physical_parameters_value directly gives the dataframe for the given test dataset\r\n",
        "\r\n",
        "def physical_parameters_value (data):\r\n",
        "  index_da = ['Case1','Case2','Case3']\r\n",
        "  T_mass = model1.predict(data)\r\n",
        "  Ni_mass = model2.predict(data)\r\n",
        "  Explosion_energy = model3.predict(data)\r\n",
        "  Snela_energy_flag = labelencoder.inverse_transform(model4.predict(data))\r\n",
        "  Ni_energy_flag = labelencoder.inverse_transform(model5.predict(data))\r\n",
        "  \r\n",
        "  #labelencoder.inverse_transform reverse the hot-encoded effect\r\n",
        "\r\n",
        "  dataframe = pd.DataFrame(list(zip(T_mass,Ni_mass,Explosion_energy,Snela_energy_flag,Ni_energy_flag)),index = index_da, columns = ['Total Mass','Ni Mass','Explosion Energy','Snela Mass distribution Flag','Ni Mass distribution Flag'])\r\n",
        "  return dataframe"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtfdNkbmb8dG"
      },
      "source": [
        "predicted_value = physical_parameters_value(test)\r\n",
        "predicted_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJftDsJscJpr"
      },
      "source": [
        "predicted_value.to_csv(\"predicted_value.csv\", index = True, header = True)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBrI9WfucMGi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}