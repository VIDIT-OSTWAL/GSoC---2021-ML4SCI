{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML4SCI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z29wjH3N5Q0"
      },
      "source": [
        "***Importing important Libraries***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-aMZDq8is4X"
      },
      "source": [
        "# importing important libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LassoCV\n",
        "from yellowbrick.regressor import AlphaSelection\n",
        "from sklearn.linear_model import Ridge\n",
        "from yellowbrick.regressor import ManualAlphaSelection\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r03NWN-gOWoQ"
      },
      "source": [
        "***Two dataset are made named 'dataset' and 'dataset1'***\n",
        "\n",
        "'dataset1' is used for training the model \n",
        "\n",
        "'dataset' is used for visualizing the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l2UIEd3i7nY"
      },
      "source": [
        "# columns are given as names as given in pdf file\n",
        "#two dataset file, dataset and dataset1 are made one for visualization and other one for modeling.\n",
        "\n",
        "my_cols = ['Param1','Param1_un','Param2','Param2_un','Param3','TMass','NiMass','Explosion energy','Snela Mass','Ni Mass']\n",
        "dataset = pd.read_csv(\"/content/dataset.csv\", header  = None,usecols= range(10), names = my_cols)\n",
        "dataset1 = pd.read_csv(\"/content/dataset.csv\", header  = None,usecols= range(10), names = my_cols )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-rQAPTnPiZs"
      },
      "source": [
        "***All the observable paraemters in 'dataset' are standarized***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWUruj93nNVH"
      },
      "source": [
        "# optical depth, maximum velocity and emergent flux of gamma-rays are standarized for smooth modelling\n",
        "# dataset is used for data visualization\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "dataset[['Param1','Param2','Param3']] = MinMaxScaler().fit_transform(dataset[['Param1','Param2','Param3']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCL62UvuQOcp"
      },
      "source": [
        "***All the parameters which are standarized are plotted in a single plot***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H1AO_AokcXM"
      },
      "source": [
        "# the observable variables are plotted against each other\n",
        "# kde plot of seaborn is used for plotting \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8,5), dpi= 80)\n",
        "sns.kdeplot(dataset[\"Param1\"], shade=True, color=\"g\", label=\"Optical depth\", alpha=.6)\n",
        "sns.kdeplot(dataset[\"Param2\"], shade=True, color=\"r\", label=\"V max\", alpha=.6)\n",
        "sns.kdeplot(dataset[\"Param3\"], shade=True, color=\"b\", label=\"Flux of gamma rays\", alpha=.6)\n",
        "plt.xlabel('Standarize value')\n",
        "plt.title('Observable Parameters plotted against each other (standarize)')\n",
        "plt.legend()\n",
        "plt.savefig(\"Observable Parameters Plotted \",dpi = 300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikq_ak_wQo0_"
      },
      "source": [
        "**Now each observable parameter is plotted seperately with their errors.**\n",
        "\n",
        "***The data of dataset1 is used as non-standarize data is plotted.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o01G91JRDWe"
      },
      "source": [
        "***Observabel parameter 'Optical Depth' is plotted.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcWDKeIwxRGF"
      },
      "source": [
        "# optical depth value is plotted with adding errors \n",
        "# no standarization has been done\n",
        "# kde has been used again\n",
        "\n",
        "plt.figure(figsize=(8,5), dpi= 80)\n",
        "sns.kdeplot(dataset1[\"Param1\"], shade=True, color=\"g\", label=\" Actual Optical depth\", alpha=1)\n",
        "sns.kdeplot(dataset1[\"Param1\"] + dataset1[\"Param1_un\"], shade=True,label=\"with positive error\", color=\"b\", alpha=.6)\n",
        "sns.kdeplot(dataset1[\"Param1\"] - dataset1[\"Param1_un\"], shade=True,label=\"with negative error\" ,color=\"r\", alpha=.6)\n",
        "plt.xlabel('Actual value')\n",
        "plt.title('Optical depth plotted ( not standarize)')\n",
        "plt.legend()\n",
        "plt.savefig(\"Optical depth Plotted \",dpi = 300)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBanpzyzRku3"
      },
      "source": [
        "***Observable parameter maximum velocity is plotted***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqCgY2ho4ZNN"
      },
      "source": [
        "# V max value is plotted with adding errors \n",
        "# no standarization has been done\n",
        "# kde has been used again\n",
        "\n",
        "plt.figure(figsize=(8,5), dpi= 80)\n",
        "sns.kdeplot(dataset1[\"Param2\"], shade=True, color=\"g\", label=\"Actual V max\", alpha=1)\n",
        "sns.kdeplot(dataset1[\"Param2\"] + dataset1[\"Param2_un\"], shade=True, color=\"b\", label=\"with positive error\", alpha=.6)\n",
        "sns.kdeplot(dataset1[\"Param2\"] - dataset1[\"Param2_un\"], shade=True, color=\"r\", label=\"with negative error\", alpha=.6)\n",
        "plt.xlabel('Actual value')\n",
        "plt.title('Velocity max plotted ( not standarize)')\n",
        "plt.legend()\n",
        "plt.savefig(\"Velocity max Plotted \",dpi = 300)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHheiqPzRuVE"
      },
      "source": [
        "***Observable parameter emergent flux of Gamma Ray is plotted***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5lCqBR66nYW"
      },
      "source": [
        "# emergent flux of gamma rays is plotted  \n",
        "# no standarization has been done\n",
        "# kde has been used again\n",
        "\n",
        "plt.figure(figsize=(8,5), dpi= 80)\n",
        "sns.kdeplot(dataset1[\"Param3\"], shade=True, color=\"c\", label=\"Emergent flux of gamma\", alpha=0.8)\n",
        "plt.xlabel('Actual value')\n",
        "plt.title('Emergent Flux of Gamma plotted ( not standarize)')\n",
        "plt.legend()\n",
        "plt.savefig(\"Emrergent Flux\",dpi = 300)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajSFiq9rR_sI"
      },
      "source": [
        "***A coorelation heat map is made with non-standarize data (dataset1)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi3aSixHD_dX"
      },
      "source": [
        "# Correlation heatmap has been made\n",
        "\n",
        "plt.figure(figsize=(8,5), dpi= 80)\n",
        "sns.heatmap(dataset1.corr(), annot = True,square=True,cmap= 'coolwarm')\n",
        "plt.title('Correlation heatmap', fontsize = 28)\n",
        "plt.savefig(\"Correlation Heatmap\",dpi = 300)\n",
        "dataset1.corr().to_csv(\"correlation.csv\",index = True, header = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYe4BnaXSOkw"
      },
      "source": [
        "***Feature Encoding is done with two cloumn SNela and Ni Mass Flag Distribution***\n",
        "\n",
        "***The feature encoding is attached as label to 'dataset'***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyBs1BOwGDmi"
      },
      "source": [
        "# Snela Mass distribution flag  and Ni Mass distribution  flag is hot encoded.\n",
        "# LabelEncoder() is used \n",
        "# the hot-encoding is attached to dataset with column name \"Snela Flag Label\" and \"Ni Flag Label\" \n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "dataset[\"Snela Flag label\"] = labelencoder.fit_transform(dataset1[\"Snela Mass\"])\n",
        "dataset[\"Ni Flag label\"] = labelencoder.fit_transform(dataset1[\"Ni Mass\"])\n",
        "labelencoder.transform(['N100', 'hed8', 'mwd' ,'w7dt'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO8PLm2vTaHW"
      },
      "source": [
        "***To get more insight of the data, now we are going to seperate the data, with different classes in SNela Mass flag distribution and Ni Mass flag distribution and plot their obserable parameters, each column has 4 different classes and therefore and thier are 2 columns therefore, in total 8 plots will be made with their observable parameters all plotted in single plot.***\n",
        "\n",
        "***For making the graph we will use standarize data of 'dataset' as different observable parameters are need to be plotted against each other.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOLfbpzzUvy5"
      },
      "source": [
        "***To seperate the dataset we are going to use two 'for' loops one looping under another, and both the loops will loop over 'list' and 'list1' as made in the following cell***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv34JPGnOchz"
      },
      "source": [
        "# two list are initialized\n",
        "# one for going over type of flag and another one for going over which mass distribution\n",
        "\n",
        "list11 = list(labelencoder.classes_)\n",
        "list12 = list(['Snela Mass','Ni Mass'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2K65k4bQ1Lq"
      },
      "source": [
        "# graphs are made to analyze how a type of flag ['N100', 'hed8', 'mwd' ,'w7dt'] in both of \"Snela Mass Flag\" or \"Ni Mass Flag\" varies with \n",
        "# observable parameters\n",
        "# two for loops are made one for going over \"Snela Mass Flag\" or \"Ni Mass Flag\" and another one for going over type of flag ['N100', 'hed8', 'mwd' ,'w7dt']\n",
        "# total 8 graphs are made\n",
        "\n",
        "for outer_index in range(2):\n",
        "  for inner_index in range(4):\n",
        "    plt.figure(figsize=(8,5), dpi= 80)\n",
        "    data_index = dataset[dataset[list12[outer_index]] == list11[inner_index]]\n",
        "    plot = sns.kdeplot(data_index[\"Param1\"], shade=True, color=\"g\", label=\"Optical depth\", alpha=.6)\n",
        "    sns.kdeplot(data_index[\"Param2\"], shade=True, color=\"r\", label=\"V max\", alpha=.6)\n",
        "    sns.kdeplot(data_index[\"Param3\"], shade=True, color=\"b\", label=\"Flux of gamma rays\", alpha=.6)\n",
        "    plt.title('graph of ' + str(list12[outer_index]) + ' flag distribution of type ' + str(list11[inner_index]))\n",
        "    plt.xlabel('Actual value (not standarize)')\n",
        "    data_index.corr().to_csv(str(list12[outer_index]) +\" \"+ str(list11[inner_index] + \".csv\"),index = True,header = True)\n",
        "    plt.legend()\n",
        "    plt.savefig(str(list12[outer_index]) +\" \" +  str(list11[inner_index]),dpi = 300)\n",
        "    plt.show()\n",
        "    #plot.get_figure().clf()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swlrHLQzWOsk"
      },
      "source": [
        "***Feature Encoding is attached to dataset1 which is going to be used for training the model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA9gzm4uPIlA"
      },
      "source": [
        "# dataset1 is used for modelling process as 'dataset' standarize and we don't need standarize data for linear regression and \n",
        "# RandomForestClassifier is already, one hot encoding is attached with \"Snela Flag Label\" and \"Ni Flag label\" column\n",
        "\n",
        "dataset1[\"Snela Flag label\"] = labelencoder.fit_transform(dataset1[\"Snela Mass\"])\n",
        "dataset1[\"Ni Flag label\"] = labelencoder.fit_transform(dataset1[\"Ni Mass\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3kxKiW3XSx4"
      },
      "source": [
        "***Three list are made.***\n",
        "\n",
        "***A list of all physical parameters, list of all observable parameters, and a list of all name of all model of physical parameters.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysjTtYFtPsnu"
      },
      "source": [
        "# physical_parameters is list of all physical parameters\n",
        "# columns is list of cloumn names of all the observable parameters \n",
        "# model is list of models which function linear_regression_compression  will make\n",
        "\n",
        "physical_parameters = ['TMass','NiMass','Explosion energy',\"Snela Flag label\",\"Ni Flag label\"]\n",
        "columns = ['Param1','Param2','Param3']\n",
        "model = ['model_TMass','model_Nimass','model_explosion energy','model_Snela_flag','model_Ni_flag']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl2dOD8dYa7_"
      },
      "source": [
        "***A function is made which return the efficiency of a regression model, when input of actual valeus and predicted values are fed to this function.***\n",
        "\n",
        "***The function return MAE (Mean Absolute Error), MSE (Mean Squared Error), RMSE (Root - Mean Squared Error)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ_u4SVxzJor"
      },
      "source": [
        "# a function metric_evaluation is made to compare the regression model efficiency\n",
        "# this function will be called in another function \n",
        "\n",
        "def metric_evaluation (y_test,pred):\n",
        "  a = metrics.mean_absolute_error(y_test,pred)\n",
        "  b = metrics.mean_squared_error(y_test,pred)\n",
        "  c = np.sqrt(metrics.mean_squared_error(y_test,pred))\n",
        "  return [a,b,c]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU1t5mMPZ_JK"
      },
      "source": [
        "***A function is made which return models of all physical parameters***\n",
        "\n",
        "***Function just need dataset, it will itself divide it into train and test dataset, for making different models, two 'for' iteration will be done one iterating over continous physical parameters and other one iterating over class based physical parameters.***\n",
        "\n",
        "***All the models will be returned in a form of list.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da2L_AdnU5gK"
      },
      "source": [
        "# linear_regression_model directly gives all the models and the efficiency of a particular model when train and test dataset are fed to this function.\n",
        "def linear_regression_comparision (given_data):\n",
        "\n",
        "# two for loops are made one for making linear regression models and another one for classification model (RandomforestClassifier is used)\n",
        "# data is splitted with train_test_split in ratio of 0.2 and only selected data is given.\n",
        "# selected data means that all observable parameters and the physical parameters which is needed is only given for training and testing\n",
        "\n",
        "  for indexing in range(3):\n",
        "  \n",
        "    X_train, X_test, y_train, y_test = train_test_split(given_data[columns],given_data[physical_parameters[indexing]] ,test_size = 0.2,random_state = 45)\n",
        "    \n",
        "    # train and test data are standarize after splitting to avoid any type of baisness one dataset can put into another\n",
        "    \n",
        "    \n",
        "    #X_train = scaler.fit_transform(X_train)\n",
        "    #X_test = scaler1.fit_transform(X_test)\n",
        "\n",
        "    print(physical_parameters[indexing])\n",
        "    \n",
        "    print(\"linear_regression\")\n",
        "    model[indexing] = linear_model.LinearRegression()\n",
        "    model[indexing].fit(X_train,y_train)\n",
        "    pred = model[indexing].predict(X_test)\n",
        "    \n",
        "    # metric_evaluaiton function is called to evaluate the model\n",
        "\n",
        "    MAE, MSE , RSQUARE = metric_evaluation(y_test,pred)\n",
        "    print(\"MAE =\" , MAE,\"MSE = \", MSE ,\"RSQUARE = \",RSQUARE)\n",
        "    print(\"--------\")\n",
        "\n",
        "  for index in range(2):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(given_data[columns],given_data[physical_parameters[index + 3]] ,test_size = 0.2,random_state = 45)\n",
        "   \n",
        "    # in RandomForestClassifier we have not standarization of data has been done\n",
        "\n",
        "    print(physical_parameters[index + 3])\n",
        "    print(\"Random Forest Classifier\")\n",
        "    \n",
        "    # n_estimators = 500\n",
        "\n",
        "    model[index + 3]=RandomForestClassifier(n_estimators=500)\n",
        "    model[index + 3].fit(X_train,y_train)\n",
        "    pred=model[index + 3].predict(X_test) \n",
        "    \n",
        "    print(\"Accuracy:\",metrics.accuracy_score(y_test, pred))\n",
        "    print(\"----------\")\n",
        "\n",
        "  # all the models which are made for each physical parameters are returned \n",
        "  return model\n",
        "\n",
        "    # lasso and ridge are not suggessted as these models are used when number of input variable are very large (around 12-15), here 3\n",
        "    # the change in alpha value literally did not affected much when tried on this dataset\n",
        "\n",
        "\n",
        "    #lasso = LassoCV(alphas=alphas)\n",
        "    #visualizer = AlphaSelection(lasso)\n",
        "    #visualizer.fit(X_train, y_train)\n",
        "    #plt.legend()\n",
        "    #visualizer.show()\n",
        "\n",
        "    #Ridge_model = ManualAlphaSelection(Ridge(),alphas=alphas,cv=12,scoring=\"neg_mean_squared_error\")\n",
        "    #Ridge_model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INeY5OkFcfkQ"
      },
      "source": [
        "***Above function is fed 'dataset1' the non - standarize data.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhWtEkqKkdqP"
      },
      "source": [
        "model1,model2,model3,model4,model5 =  linear_regression_comparision(dataset1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WL7NcvQ5dKZV"
      },
      "source": [
        "***The test data is converted to pandas.DataFrame***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tziTSzFBA4kH"
      },
      "source": [
        "data = [[3.35,0.015,0.000012],[2.54,0.013,0.00000502],[2.46,0.013,0.0000103]]\n",
        "test = pd.DataFrame(data,columns = ['Param1','Param2','Param3'])\n",
        "test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HgI5twAdTE-"
      },
      "source": [
        "***A function is made which outputs a dataframe of all physical parameters predicted when dataset is fed to it, class columns are inversely transformed to get the classes of SNela and Ni Mass Flag Distribution.***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idJaYECkPPE5"
      },
      "source": [
        "#physical_parameters_value directly gives the dataframe for the given test dataset\n",
        "\n",
        "def physical_parameters_value (data):\n",
        "  index_da = ['Case1','Case2','Case3']\n",
        "  T_mass = model1.predict(data)\n",
        "  Ni_mass = model2.predict(data)\n",
        "  Explosion_energy = model3.predict(data)\n",
        "  Snela_energy_flag = labelencoder.inverse_transform(model4.predict(data))\n",
        "  Ni_energy_flag = labelencoder.inverse_transform(model5.predict(data))\n",
        "  \n",
        "  #labelencoder.inverse_transform reverse the hot-encoded effect\n",
        "\n",
        "  dataframe = pd.DataFrame(list(zip(T_mass,Ni_mass,Explosion_energy,Snela_energy_flag,Ni_energy_flag)),index = index_da, columns = ['Total Mass','Ni Mass','Explosion Energy','Snela Mass distribution Flag','Ni Mass distribution Flag'])\n",
        "  return dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtfdNkbmb8dG"
      },
      "source": [
        "predicted_value = physical_parameters_value(test)\n",
        "predicted_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBul295TeRv1"
      },
      "source": [
        "***The predicted dataframe is exported in a '.csv' format***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJftDsJscJpr"
      },
      "source": [
        "predicted_value.to_csv(\"predicted_value.csv\", index = True, header = True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}